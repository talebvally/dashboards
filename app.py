# -*- coding: utf-8 -*-
"""Untitled76.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/149Ak0Iw9BTsgkFoE1XgnNs0gxJlF1wmu

## 1.instalation
"""

!pip install mysql-connector-python pandas matplotlib seaborn
!pip install dash pandas
!pip install plotly
!pip install plotly ipywidgets pandas
!pip install pyvista
!pip install vedo
!pip install jupyter-dash dash --quiet
!pip install plotly ipywidgets pandas
!pip install dash plotly pandas
!pip install -U kaleido
!pip install --upgrade dash plotly pandas

"""##2.Connexion ferm√©e"""

import mysql.connector
import pandas as pd
config = {
    'user': 'ap6ei_taleb',
    'password': '1Z_z8H~z7a$N@x',
    'host': 'ap6ei.myd.infomaniak.com',
    'database': 'ap6ei_test_delil',
}
try:
    cnx = mysql.connector.connect(**config)
    print("Connexion r√©ussie !")

    query = "SELECT COUNT(*) AS nombre_de_tables FROM information_schema.tables WHERE table_schema = 'ap6ei_test_delil'"
    df = pd.read_sql(query, cnx)
    print(df.head())

except Exception as e:
    print("Erreur lors de la connexion :", e)

finally:
    if 'cnx' in locals() and cnx.is_connected():
        cnx.close()
        print("Connexion ferm√©e.")

"""## 2.Tables"""

import mysql.connector
import pandas as pd
config = {
    'user': 'ap6ei_taleb',
    'password': '1Z_z8H~z7a$N@x',
    'host': 'ap6ei.myd.infomaniak.com',
    'database': 'ap6ei_test_delil',
   }
try:

    cnx = mysql.connector.connect(**config)
    print("Connexion r√©ussie !")

    query = "show full Tables"
    df = pd.read_sql(query, cnx)
    print(df.to_string())

except Exception as e:
    print("Erreur lors de la connexion :", e)

finally:
    if 'cnx' in locals() and cnx.is_connected():
        cnx.close()
        print("Connexion ferm√©e.")



"""## 3.v√©rification  ligne vide"""

import mysql.connector


config = {
    'user': 'ap6ei_taleb',
    'password': '1Z_z8H~z7a$N@x',
    'host': 'ap6ei.myd.infomaniak.com',
    'database': 'ap6ei_test_delil',

}

try:

    cnx = mysql.connector.connect(**config)
    cursor = cnx.cursor()


    cursor.execute("SHOW TABLES")
    tables = cursor.fetchall()

    for (table_name,) in tables:
        print(f"\nTable: {table_name}")


        cursor.execute(f"DESCRIBE {table_name}")
        columns = cursor.fetchall()
        column_names = [column[0] for column in columns]


        conditions = " AND ".join([f"({col} IS NULL OR {col} = '')" for col in column_names])
        query = f"SELECT * FROM {table_name} WHERE {conditions}"


        cursor.execute(query)
        rows = cursor.fetchall()

        if rows:
            for row in rows:
                print(row)
        else:
            print("Aucune ligne vide trouv√©e.")

except mysql.connector.Error as err:
    print(f"Erreur lors de la connexion ou de l'ex√©cution des requ√™tes : {err}")
finally:
    if 'cnx' in locals() and cnx.is_connected():
        cursor.close()
        cnx.close()
        print("Connexion ferm√©e.")

"""!pip install pygwalker"""

!pip install pandas mysql-connector-python matplotlib seaborn plotly numpy

"""## 4.demendeur_emplois"""

!pip install pymysql
import pymysql
import pandas as pd


conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)

df = pd.read_sql("SELECT * FROM demendeur_emplois", conn)


conn.close()

df.head()

total_elements = df.size
print(f"Le DataFrame contient au total {total_elements} √©l√©ments.")

"""## 5.Le DataFrame df_dem

"""

n_lignes, n_colonnes = df.shape
print(f"Le DataFrame contient {n_lignes} lignes et {n_colonnes} colonnes.")

"""##6.1.Histogramme des agent_id color√© par agence"""

import plotly.express as px
import plotly.io as pio


pio.renderers.default = "colab"


fig = px.histogram(
    df,
    x="agence_id",
    color="agence_id",
    nbins=df["agence_id"].nunique(),
    title="Histogramme des agent_id color√© par agence",
    labels={
        "agent_id": "ID Agent",
        "count": "Effectif",
        "agence_id": "ID Agence"
    },
    barmode="group"
)


fig.show()

"""##6.2.Nombre de demandeurs par agence"""

df_dem = df
# Connect to the database
conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)

# Read data into a pandas DataFrame
df_ag = pd.read_sql("SELECT * FROM  agences", conn)

!pip install IPython

!pip install ipywidgets --quiet

from ipywidgets import Output

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from ipywidgets import Output
from IPython.display import display

df = df_dem.merge(
    df_ag[['id', 'libelle']].rename(columns={'id': 'agence_id', 'libelle': 'nom_agence'}),
    how='left',
    on='agence_id'
)

counts = df.groupby('agence_id').agg({
    'nom_agence': 'first',
    'id': 'count'
}).reset_index().rename(columns={'id': 'effectif'})

!pip  install anywidget

fig = go.FigureWidget(
    px.bar(
        counts,
        x='agence_id',
        y='effectif',
        color='agence_id',
        hover_data=['nom_agence', 'effectif'],
        labels={'agence_id': 'ID Agence', 'effectif': 'Nombre de demandeurs'},
        title="Nombre de demandeurs par agence"
    )
)

out = Output(layout={'border': '1px solid gray', 'padding': '10px'})
display(fig, out)

def on_bar_click(trace, points, state):
    if not points.point_inds:
        return
    idx = points.point_inds[0]
    agence_sel = counts.loc[idx, 'agence_id']
    nom_sel = "Agence " + counts.loc[idx, 'nom_agence']
    subset = df[df['agence_id'] == agence_sel]
    with out:
        out.clear_output()
        print(f"üÜî Agence : {agence_sel}")
        print(f"üè∑Ô∏è Nom    : {nom_sel}")
        print(f"üë• Total demandeurs : {len(subset)}")
        display(subset[['id', 'nom', 'prenom']].head(10))

fig.data[0].on_click(on_bar_click)

fig.show()

conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)


df_dom= pd.read_sql("SELECT * FROM  domaines ", conn)
df_sec=pd.read_sql("SELECT * FROM   secteurs  ", conn)



"""## 7.1.R√©partition des demandeurs d'emploi par Secteur"""

import pandas as pd
import plotly.express as px

df_dem['secteur'] = df_dem['secteur'].fillna('Sans secteur')


domaine_counts = df_dem['secteur'].value_counts().reset_index()
domaine_counts.columns = ['secteur', 'Effectif']


fig = px.pie(
    domaine_counts,
    names='secteur',
    values='Effectif',
    title="R√©partition des demandeurs d'emploi par domaine",
    hole=0.4
)

fig.update_traces(textinfo='percent+label')
fig.update_traces(textinfo='label+percent+value', textposition='inside')

fig.show()

"""
#7.2.√âvolution mensuelle des  comptes de demandeurs d'emploi"""

import pandas as pd
import plotly.express as px
import geopandas as gpd
import matplotlib.pyplot as plt
import seaborn as sns
import pymysql
import pandas as pd


conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)
df_employer= pd.read_sql("SELECT * FROM  employeurs ", conn)
df_offres= pd.read_sql("SELECT * FROM  offres ", conn)
geo_wilaya=pd.read_sql("SELECT * FROM  pej_ref_wilayas ", conn)
df_demandeurs_emplois= pd.read_sql("SELECT * FROM  demendeur_emplois ", conn)

import pandas as pd


df_demandeurs_emplois['created_at'] = pd.to_datetime(df_demandeurs_emplois['created_at'])

start_date = pd.Timestamp.today() - pd.DateOffset(months=6)
df_period = df_demandeurs_emplois[df_demandeurs_emplois['created_at'] >= start_date]

ts_monthly = (
    df_period
    .groupby(df_period['created_at'].dt.to_period('M'))
    .size()
    .reset_index(name='new_demandeurs')
)
ts_monthly['created_at'] = ts_monthly['created_at'].dt.to_timestamp()

import pandas as pd
import plotly.graph_objects as go
df = df_demandeurs_emplois.copy()
df['created_at'] = pd.to_datetime(df['created_at'])
df['period'] = df['created_at'].dt.to_period('M').astype(str)

ts = (
    df
    .groupby('period')
    .size()
    .reset_index(name='new_demandeurs')
)

ts = ts.sort_values('period')


fig = go.Figure()

fig.add_trace(go.Scatter(
    x=ts['period'],
    y=ts['new_demandeurs'],
    mode='lines+markers',
    name='Nouveaux comptes',
    hovertemplate='<b>P√©riode</b>: %{x}<br><b>Nb comptes</b>: %{y}<extra></extra>'
))

fig.update_layout(
    title="√âvolution mensuelle des  comptes de demandeurs d'emploi",
    xaxis_title="P√©riode (Ann√©e-Mois)",
    yaxis_title="Nouveaux comptes",
    xaxis=dict(
        tickangle=-45,
        rangeslider=dict(visible=True),
        type='category',
        rangeselector=dict(
            buttons=[
                dict(count=3, label="3 mois", step="month", stepmode="backward"),
                dict(count=6, label="6 mois", step="month", stepmode="backward"),
                dict(count=1, label="1 an", step="year", stepmode="backward"),
                dict(step="all", label="Tous")
            ]
        )
    ),
    margin=dict(l=40, r=40, t=60, b=120)
)

fig.show()

"""#8.1.√âvolution mensuelle des  comptes demendeurs d'emplois par agnece et agent"""

import pandas as pd
from dash import Dash, dcc, html, Output, Input
import plotly.graph_objects as go


conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)

df_agences= pd.read_sql("SELECT * FROM  agences ", conn)
df_agents= pd.read_sql("SELECT * FROM  agents ", conn)


df = df_demandeurs_emplois.copy()
df['created_at'] = pd.to_datetime(df['created_at'])
df['period'] = df['created_at'].dt.to_period('M').astype(str)

df_ag = df_agences.rename(columns={'id':'agence_id','libelle':'AgenceName'})
df_ag_lookup = df_ag[['agence_id','AgenceName']].assign(type='Agence') \
                       .rename(columns={'agence_id':'id','AgenceName':'name'})

df_agnt = df_agents.rename(columns={'id':'agent_id','nom':'AgentName'})
df_agnt = df_agnt.merge(df_ag[['agence_id','AgenceName']], on='agence_id', how='left')
df_agnt_lookup = df_agnt[['agent_id','AgentName','AgenceName']].assign(type='Agent') \
                         .rename(columns={'agent_id':'id','AgentName':'name'})


lookup = pd.concat([df_ag_lookup, df_agnt_lookup], ignore_index=True)

ts_agence = (
    df.groupby(['period','agence_id'])
      .size().reset_index(name='new_demandeurs')
      .merge(df_ag_lookup.rename(columns={'id':'agence_id','name':'AgenceName'})[['agence_id','AgenceName']],
             on='agence_id', how='left')
)
ts_agent = (
    df.groupby(['period','agent_id'])
      .size().reset_index(name='new_demandeurs')
      .merge(df_agnt_lookup.rename(columns={'id':'agent_id','name':'AgentName'})[['agent_id','AgentName','AgenceName']],
             on='agent_id', how='left')
)
app = Dash(__name__)

app.layout = html.Div([
    html.H3("√âvolution mensuelle des comptes par agence et agent"),
    dcc.Dropdown(
        id='multi-selector',
        options=[
            {'label': f"{row['type']} : {row['name']} (ID {row['id']})",
             'value': f"{row['type']}|{row['id']}"}
            for _, row in lookup.iterrows()
        ],
        placeholder="S√©lectionnez une ou plusieurs entit√©s‚Ä¶",
        searchable=True,
        multi=True,
        style={'width':'60%'}
    ),
    dcc.Graph(id='comparison-graph')
])


@app.callback(
    Output('comparison-graph','figure'),
    Input('multi-selector','value')
)
def update_comparison(selection):
    fig = go.Figure()
    if not selection:
        return fig


    for sel in selection:
        kind, idx = sel.split('|')
        idx = int(idx)
        if kind == 'Agence':
            d = ts_agence[ts_agence['agence_id'] == idx]
            label = d['AgenceName'].iloc[0]
            custom = d[['AgenceName','agence_id']].values
            hover = (
                "<b>Agence</b>: %{customdata[0]}<br>"
                "<b>ID Agence</b>: %{customdata[1]}<br>"
                "<b>P√©riode</b>: %{x}<br>"
                "<b>Nombre des comptes valid√© </b>: %{y}<extra></extra>"
            )
        else:  # Agent
            d = ts_agent[ts_agent['agent_id'] == idx]
            label = d['AgentName'].iloc[0]
            custom = d[['AgentName','agent_id','AgenceName']].values
            hover = (
                "<b>Agent</b>: %{customdata[0]}<br>"
                "<b>ID Agent</b>: %{customdata[1]}<br>"
                "<b>Agence</b>: %{customdata[2]}<br>"
                "<b>P√©riode</b>: %{x}<br>"
                "<b>Nombre des comptes valid√©</b>: %{y}<extra></extra>"
            )


        fig.add_trace(go.Scatter(
            x=d['period'], y=d['new_demandeurs'],
            mode='lines+markers',
            name=f"{kind} {label}",
            customdata=custom,
            hovertemplate=hover
        ))

    # Mise en forme finale
    fig.update_layout(
        title="√âvolution mensuelle des demendeurs d'emplois par agnece et agent ",
        xaxis=dict(
            title="P√©riode (YYYY-MM)",
            type='category',
            tickangle=-45,
            rangeslider=dict(visible=True)
        ),
        yaxis=dict(title="Demendeurs empois "),
        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)
    )
    return fig

# Lancement ---
if __name__ == '__main__':
    app.run(debug=True)

"""#8.2.√âvolution Mensuelle des Offres Publi√©e"""

df_offres['date_publication'] = pd.to_datetime(df_offres['date_publication'])
time_series = df_offres.groupby(df_offres['date_publication'].dt.to_period("M")).size().reset_index(name="count")
time_series['date_publication'] = time_series['date_publication'].dt.to_timestamp()
fig8 = px.line(
    time_series,
    x="date_publication",
    y="count",
    title="√âvolution Mensuelle des Offres Publi√©es"
)
fig8.show()

import pandas as pd
from dash import Dash, dcc, html, Output, Input
import plotly.graph_objects as go

df_off = df_offres.copy()

df_off['date_publication'] = pd.to_datetime(df_off['date_publication'])

df_off['period'] = df_off['date_publication'].dt.to_period('M').astype(str)


df_ag = df_agences.rename(columns={'id':'agence_id', 'libelle':'AgenceName'})
df_ag_lookup = df_ag[['agence_id','AgenceName']].assign(type='Agence') \
                       .rename(columns={'agence_id':'id','AgenceName':'name'})


df_agnt = df_agents.rename(columns={'id':'agent_id','nom':'AgentName'})
df_agnt = df_agnt.merge(df_ag[['agence_id','AgenceName']], on='agence_id', how='left')
df_agnt_lookup = df_agnt[['agent_id','AgentName','AgenceName']].assign(type='Agent') \
                         .rename(columns={'agent_id':'id','AgentName':'name'})

lookup = pd.concat([df_ag_lookup, df_agnt_lookup], ignore_index=True)

ts_agence = (
    df_off.groupby(['period','agence_id'])
          .size().reset_index(name='nb_offres')
          .merge(df_ag_lookup.rename(columns={'id':'agence_id','name':'AgenceName'})[['agence_id','AgenceName']],
                 on='agence_id', how='left')
)
ts_agent = (
    df_off.groupby(['period','agent_id'])
          .size().reset_index(name='nb_offres')
          .merge(df_agnt_lookup.rename(columns={'id':'agent_id','name':'AgentName'})[['agent_id','AgentName','AgenceName']],
                 on='agent_id', how='left')
)


app = Dash(__name__)

app.layout = html.Div([
    html.H3("√âvolution mensuelle du nombre d‚Äôoffres par agence et agent"),
    dcc.Dropdown(
        id='multi-selector',
        options=[
            {'label': f"{row['type']} : {row['name']} (ID {row['id']})",
             'value': f"{row['type']}|{row['id']}"}
            for _, row in lookup.iterrows()
        ],
        placeholder="S√©lectionnez une ou plusieurs entit√©s‚Ä¶",
        searchable=True,
        multi=True,
        style={'width':'60%'}
    ),
    dcc.Graph(id='comparison-graph')
])


@app.callback(
    Output('comparison-graph','figure'),
    Input('multi-selector','value')
)
def update_comparison(selection):
    fig = go.Figure()
    if not selection:
        return fig

    for sel in selection:
        kind, idx = sel.split('|')
        idx = int(idx)
        if kind == 'Agence':
            d = ts_agence[ts_agence['agence_id'] == idx]
            label = d['AgenceName'].iloc[0]
            custom = d[['AgenceName','agence_id']].values
            hover = (
                "<b>Agence</b>: %{customdata[0]}<br>"
                "<b>ID Agence</b>: %{customdata[1]}<br>"
                "<b>P√©riode</b>: %{x}<br>"
                "<b>Nombre d'offres</b>: %{y}<extra></extra>"
            )
        else:  # Agent
            d = ts_agent[ts_agent['agent_id'] == idx]
            label = d['AgentName'].iloc[0]
            custom = d[['AgentName','agent_id','AgenceName']].values
            hover = (
                "<b>Agent</b>: %{customdata[0]}<br>"
                "<b>ID Agent</b>: %{customdata[1]}<br>"
                "<b>Agence</b>: %{customdata[2]}<br>"
                "<b>P√©riode</b>: %{x}<br>"
                "<b>Nombre d'offres</b>: %{y}<extra></extra>"
            )

        fig.add_trace(go.Scatter(
            x=d['period'], y=d['nb_offres'],
            mode='lines+markers',
            name=f"{kind} {label}",
            customdata=custom,
            hovertemplate=hover
        ))

    fig.update_layout(
        title="Comparaison mensuelle du nombre d‚Äôoffres",
        xaxis=dict(
            title="P√©riode (YYYY-MM)",
            type='category',
            tickangle=-45,
            rangeslider=dict(visible=True)
        ),
        yaxis=dict(title="Nombre d'offres"),
        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)
    )
    return fig

if __name__ == '__main__':
    app.run(debug=True)

df_off['ContractType'] = df_off['ref_type_contrat_id'].map({
    1: "CDI",
    2: "CDD",
    3: "Stage",
    4: "Mauritanisation"
})


pivot_ag = (
    df_off
    .groupby(['period','agence_id','ContractType'])
    .size()
    .unstack(fill_value=0)
    .reset_index()
)

pivot_agent = (
    df_off
    .groupby(['period','agent_id','ContractType'])
    .size()
    .unstack(fill_value=0)
    .reset_index()
)



"""# 9.1.agence et agent par les d√©tailles des offres

"""

import plotly.graph_objects as go


df_off = df_offres.copy()

df_off['date_publication'] = pd.to_datetime(df_off['date_publication'])

df_off['period'] = df_off['date_publication'].dt.to_period('M').astype(str)


df_ag = df_agences.rename(columns={'id':'agence_id', 'libelle':'AgenceName'})
df_ag_lookup = df_ag[['agence_id','AgenceName']].assign(type='Agence') \
                       .rename(columns={'agence_id':'id','AgenceName':'name'})

df_agnt = df_agents.rename(columns={'id':'agent_id','nom':'AgentName'})
df_agnt = df_agnt.merge(df_ag[['agence_id','AgenceName']], on='agence_id', how='left')
df_agnt_lookup = df_agnt[['agent_id','AgentName','AgenceName']].assign(type='Agent') \
                         .rename(columns={'agent_id':'id','AgentName':'name'})

lookup = pd.concat([df_ag_lookup, df_agnt_lookup], ignore_index=True)

ts_agence = (
    df_off.groupby(['period','agence_id'])
          .size().reset_index(name='nb_offres')
          .merge(df_ag_lookup.rename(columns={'id':'agence_id','name':'AgenceName'})[['agence_id','AgenceName']],
                 on='agence_id', how='left')
)
ts_agent = (
    df_off.groupby(['period','agent_id'])
          .size().reset_index(name='nb_offres')
          .merge(df_agnt_lookup.rename(columns={'id':'agent_id','name':'AgentName'})[['agent_id','AgentName','AgenceName']],
                 on='agent_id', how='left')
)

app = Dash(__name__)

app.layout = html.Div([
    html.H3("√âvolution mensuelle du nombre d‚Äôoffres par agence et agent"),
    dcc.Dropdown(
        id='multi-selector',
        options=[
            {'label': f"{row['type']} : {row['name']} (ID {row['id']})",
             'value': f"{row['type']}|{row['id']}"}
            for _, row in lookup.iterrows()
        ],
        placeholder="S√©lectionnez une ou plusieurs entit√©s‚Ä¶",
        searchable=True,
        multi=True,
        style={'width':'60%'}
    ),
    dcc.Graph(id='comparison-graph')
])
@app.callback(
    Output('comparison-graph','figure'),
    Input('multi-selector','value')
)
def update_comparison(selection):
    fig = go.Figure()
    if not selection:
        return fig

    for sel in selection:
        kind, idx = sel.split('|')
        idx = int(idx)

        if kind == 'Agence':

            d = ts_agence[ts_agence['agence_id']==idx]

            d = d.merge(
                pivot_ag[pivot_ag['agence_id']==idx],
                on='period', how='left'
            ).fillna(0)
            label = d['AgenceName'].iloc[0]


            custom = d[['AgenceName','agence_id','CDI','CDD','Stage','Mauritanisation']].values
            hover = (
                "<b>Agence</b>: %{customdata[0]}<br>"
                "<b>ID Agence</b>: %{customdata[1]}<br>"
                "<b>P√©riode</b>: %{x}<br>"
                "<b>Nb offres</b>: %{y}<br><br>"
                "<b>Par type :</b><br>"
                "CDI: %{customdata[2]}   CDD: %{customdata[3]}<br>"
                "Stage: %{customdata[4]}   Maurit.: %{customdata[5]}<extra></extra>"
            )

        else:
            d = ts_agent[ts_agent['agent_id']==idx]
            d = d.merge(
                pivot_agent[pivot_agent['agent_id']==idx],
                on='period', how='left'
            ).fillna(0)
            label = d['AgentName'].iloc[0]
            custom = d[['AgentName','agent_id','AgenceName','CDI','CDD','Stage','Mauritanisation']].values
            hover = (
                "<b>Agent</b>: %{customdata[0]}<br>"
                "<b>ID Agent</b>: %{customdata[1]}<br>"
                "<b>Agence</b>: %{customdata[2]}<br>"
                "<b>P√©riode</b>: %{x}<br>"
                "<b>Nb offres</b>: %{y}<br><br>"
                "<b>Par type :</b><br>"
                "CDI: %{customdata[3]}   CDD: %{customdata[4]}<br>"
                "Stage: %{customdata[5]}   Maurit.: %{customdata[6]}<extra></extra>"
            )

        fig.add_trace(go.Scatter(
            x=d['period'], y=d['nb_offres'],
            mode='lines+markers',
            name=f"{kind} {label}",
            customdata=custom,
            hovertemplate=hover
        ))

    fig.update_layout(
        title="Comparaison mensuelle du nombre d‚Äôoffres",
        xaxis=dict(type='category', tickangle=-45, rangeslider=dict(visible=True)),
        yaxis=dict(title="Nombre d'offres"),
        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)
    )
    return fig
if __name__ == '__main__':
    app.run(debug=True)

"""#10.1. Histogram of Number of Recruits

"""

fig3 = px.histogram(
    df_offres,
    x="nbr_recrute",
    nbins=20,
    title="Distribution du Nombre de Recrut√©s par Offre"
)
fig3.show()

"""#10.2.Stacked Bar of Offers by Sector and Contract Type

"""

import pymysql
import plotly.express as px
import pandas as pd

# --- 1. Connexion et r√©cup√©ration des donn√©es ---
conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)

# Secteurs
df_secteur = pd.read_sql("SELECT * FROM secteurs", conn)

import pandas as pd
import plotly.express as px

# --- 1. Renommer correctement votre table de secteurs ---
# df_secteur contient ['id', 'libelle', ‚Ä¶]
df_secteur_clean = df_secteur.rename(columns={
    'id': 'secteur_id',         # la cl√© √©trang√®re
    'libelle': 'secteur_name'   # le libell√© √† afficher
})

# --- 2. Fusionner pour r√©cup√©rer secteur_name dans vos offres ---
# df_offres contient 'secteur_id', 'ref_type_contrat_id', ‚Ä¶
df_offres_labeled = df_offres.merge(
    df_secteur_clean[['secteur_id','secteur_name']],
    on='secteur_id',
    how='left'
)

# --- 3. Mapper les types de contrat en texte ---
contract_map = {1: "CDD", 2: "CDI", 3: "Stage", 4: "Mauritanisation"}
df_offres_labeled['TypeContrat'] = df_offres_labeled['ref_type_contrat_id'].map(contract_map)

# --- 4. Regrouper par secteur_name et type de contrat ---
offers_sector_contract = (
    df_offres_labeled
      .groupby(['secteur_name','TypeContrat'])
      .size()
      .reset_index(name='count')
)

# --- 5. Tracer le bar chart avec secteur_name sur l‚Äôaxe X ---
fig5 = px.bar(
    offers_sector_contract,
    x="secteur_name",      # on affiche bien le libell√©
    y="count",
    color="TypeContrat",
    title="Offres par Secteur et Type de Contrat",
    labels={
        "secteur_name": "Secteur",
        "count": "Nombre d‚Äôoffres",
        "TypeContrat": "Type de contrat"
    },
    hover_data={
        "secteur_name": True,
        "count": True,
        "TypeContrat": True
    },
    color_discrete_sequence=px.colors.qualitative.Pastel
)

import plotly.express as px

fig5 = px.bar(
    offers_sector_contract,
    x="secteur_name",
    y="count",
    color="TypeContrat",
    title="Offres par Secteur et Type de Contrat",
    labels={"secteur_name":"Secteur","count":"Nombre d‚Äôoffres","TypeContrat":"Type de contrat"},
    hover_data={"count":True,"TypeContrat":True},
    color_discrete_sequence=px.colors.qualitative.Pastel,
    width=1500,    # largeur en pixels
    height=800     # hauteur en pixels :contentReference[oaicite:0]{index=0}
)
fig5.update_layout(
    xaxis_tickangle=-45,
    legend_title_text="Type de contrat"
)
fig5.show()

"""#10.3.Boxplot of Experience Required by Contract Type"""

# Map contract IDs to labels
contract_map = {1: "CDD", 2: "CDI", 3: "Stage", 4: "Mauritanisation "}
df_offres["TypeContrat"] = df_offres["ref_type_contrat_id"].map(contract_map)
fig4 = sns.boxplot(
    data=df_offres,
    x="TypeContrat",
    y="nbr_annees_experience_requis"
)
plt.title("Ann√©es d'Exp√©rience Requises par Type de Contrat")
plt.show()

"""# 10.4.Heatmap of Employer States"""

emp_state = df_employer.groupby(["ref_etat_employeur_id", "in_rim"]).size().unstack(fill_value=0)
sns.heatmap(emp_state, annot=True, fmt="d")
plt.title("R√©partition des Employeurs selon √âtat et Pr√©sence en  Mauritanie ")
plt.xlabel(" en mauritannie  mauriatanie  ")
plt.ylabel("ref_etat_employeur_id")
plt.show()

"""# 10.5. Scatter Plot Employers vs Number of Employees and Published Offers"""

off_per_employer = df_offres.groupby("employeur_id").size().reset_index(name="offre_count")
df_emp_scatter = pd.merge(df_employer, off_per_employer, left_on="id", right_on="employeur_id", how="left").fillna(0)
fig7 = px.scatter(
    df_emp_scatter,
    x="nb_employes",
    y="offre_count",
    size="offre_count",
    color="secteur_id",
    hover_name="libelle",
    title="Offres Publi√©es vs Nombre d'Employ√©s par Employeur"
)
fig7.show()

"""#11.1. Nombre d'offres par ann√©e de cr√©ation"""

import plotly.express as px
import plotly.io as pio

pio.renderers.default = "colab"
conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)

df_offres = pd.read_sql("SELECT * FROM offres", conn)

fig = px.histogram(
    df_offres,
    x='date_publication',
    histfunc='count',
    title="Nombre d'offres par ann√©e de cr√©ation",
    labels={'annee_pub': "Ann√©e", 'count': "Nombre d'offres"}
)

fig.update_layout(
    xaxis_title="Ann√©e de cr√©ation",
    yaxis_title="Nombre d'offres",
    xaxis_tickangle=-45,
    margin=dict(l=40, r=40, t=60, b=100)
)

fig.show()

"""
## 11.2Nombre d‚Äôoffres publi√©es par mois et par Ann√©"""

df_offres['year'] = df_offres['created_at'].dt.year.astype(str)          # Ann√©e au format cha√Æne :contentReference[oaicite:5]{index=5}
df_offres['month_num']  = df_offres['created_at'].dt.month              # Mois num√©rique 1‚Äì12 :contentReference[oaicite:6]{index=6}
df_offres['month_name'] = df_offres['created_at'].dt.month_name()       # Nom complet du mois :contentReference[oaicite:7]{index=7}

# Grouper par ann√©e et mois pour compter les offres
counts_month = (
    df_offres
    .groupby(['year','month_num','month_name'])
    .size()
    .reset_index(name='count')  # colonne 'count' = nombre d‚Äôoffres
)

import plotly.express as px
import plotly.io as pio


pio.renderers.default = "colab"

# Bubble Chart : mois sur X, ann√©es sur Y, taille = count
fig = px.scatter(
    counts_month,
    x='month_num',
    y='year',
    size='count',
    color='year',
    hover_name='month_name',
    hover_data={'count':True},
    size_max=60,
    title="Nombre d‚Äôoffres publi√©es par mois et par ann√©e"
)


fig.update_layout(
    xaxis = dict(
        tickmode='array',
        tickvals = counts_month['month_num'].sort_values().unique(),
        ticktext=counts_month.groupby('month_num')['month_name'].first().reindex(range(1,13)).values
    ),
    xaxis_title="Mois",
    yaxis_title="Ann√©e",
    margin=dict(l=40, r=40, t=60, b=40)
)

fig.show()



import pandas as pd

grp = (
    df_dem
    .groupby(['progress', 'nni_checked', 'ref_etat_dossier_id'])
    .size()
    .reset_index(name='count')
)

print(df_dem.head())
print("Nombre de lignes apr√®s filtre :", len(df_dem))

print(df_dem['ref_etat_dossier_id'].unique())

df_emp_clean = df_dem.dropna(subset=['progress', 'nni_checked', 'ref_etat_dossier_id'])

df_dem['progress'] = pd.to_numeric(df_dem['progress'], errors='coerce')
df_dem['nni_checked'] = pd.to_numeric(df_dem['nni_checked'], errors='coerce')
df_dem['ref_etat_dossier_id'] = pd.to_numeric(df_dem['ref_etat_dossier_id'], errors='coerce')

# Supprimer les lignes vides
df_emp_clean = df_dem.dropna(subset=['progress', 'nni_checked', 'ref_etat_dossier_id'])

df_dem.head()

conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)


df_employer= pd.read_sql("SELECT * FROM  employeurs ", conn)

df_employer.head()

"""*   √âl√©ment de liste
*   √âl√©ment de liste

# Analyse  des √âtats de Dossier  Manipulation 3D
"""

import dash
from dash import dcc, html, Input, Output
import plotly.graph_objects as go
import pandas as pd
import numpy as np


conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)

df_dem = pd.read_sql("SELECT * FROM demendeur_emplois", conn)
app = dash.Dash(__name__)

def prepare_data(target_state):
    df_filtered = df_dem[df_dem['ref_etat_dossier_id'] == target_state]
    df_agg = df_filtered.groupby(['progress', 'nni_checked']).size().reset_index(name='volume')

    progress_values = sorted(df_dem['progress'].dropna().unique().astype(int))
    nni_values = sorted(df_dem['nni_checked'].dropna().unique().astype(int))
    pivot_table = df_agg.pivot_table(
        index='progress',
        columns='nni_checked',
        values='volume',
        fill_value=0
    ).reindex(index=progress_values, columns=nni_values, fill_value=0)

    X, Y = np.meshgrid(progress_values, nni_values)
    Z = pivot_table.values.T

    return X.tolist(), Y.tolist(), Z.tolist()

app.layout = html.Div([
    html.H1("Analyse Interactive des √âtats de Dossier", style={'textAlign': 'center'}),
    dcc.Dropdown(
        id='state-dropdown',
        options=[{'label': f'√âtat {state}', 'value': state} for state in sorted(df_dem['ref_etat_dossier_id'].unique())],
        value=1,
        style={'width': '50%', 'margin': '20px auto'}
    ),
    dcc.Graph(id='3d-plot')
])

# Callback mis √† jour
@app.callback(
    Output('3d-plot', 'figure'),
    [Input('state-dropdown', 'value')]
)
def update_graph(selected_state):
    X, Y, Z = prepare_data(selected_state)

    fig = go.Figure(data=[go.Surface(x=X, y=Y, z=Z, colorscale='Viridis')])
    fig.update_layout(
        title=f"Volume des dossiers √† l'√©tat {selected_state}",
        scene=dict(
            xaxis_title='Progress (0-100)',
            yaxis_title='NNI Checked (0/1)',
            zaxis_title='Volume',
            camera_eye=dict(x=1.5, y=1.5, z=1.5)
        )
    )
    return fig

if __name__ == '__main__':
    app.run(debug=True)

"""#Agents par Agence"""

!pip install pymysql
import pandas as pd
import pymysql
import pandas as pd

conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)

df_agences= pd.read_sql("SELECT * FROM agences", conn)
df_agents= pd.read_sql("SELECT * FROM agents", conn)
df_agences.columns

import pymysql
import pandas as pd

# Connexion √† la base
conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)

# 1.1. Agences : id, libelle
df_agences = pd.read_sql("SELECT id AS agence_id, libelle AS agence_name FROM agences", conn)

# 1.2. Agents : id, nom, ref_fonctions_agent_id, agence_id, actif
df_agents = pd.read_sql("""
    SELECT
      id AS agent_id,
      nom,
      ref_fonctions_agent_id,
      agence_id,
      actif
    FROM agents
""", conn)

# 1.3. Mapping des r√¥les
role_map = {
    1: "Conseiller",
    2: "Chef d'agence",
    3: "Administrateur syst√®me"
}
df_agents['role'] = df_agents['ref_fonctions_agent_id'].map(role_map)

# 1.4. Filtrer les agents actifs
df_active = df_agents[df_agents['actif'] == 1]

# 1.5. Comptages globaux
total_agences = df_agences['agence_id'].nunique()
total_agents_actifs = df_active['agent_id'].nunique()

# 1.6. Comptage par agence et r√¥le
counts_by_agence = (
    df_active
    .groupby(['agence_id', 'role'])
    .size()
    .reset_index(name='count')
)
from dash import Dash, dcc, html, dash_table, Input, Output
import plotly.express as px

app = Dash(__name__, suppress_callback_exceptions=True)

# Dropdown : options d'agences + "Toutes"
options = [{'label': 'Toutes', 'value': 'ALL'}] + [
    {'label': f"{row.agence_name} (ID {row.agence_id})", 'value': row.agence_id}
    for row in df_agences.itertuples()
]

app.layout = html.Div([
    html.H1("Dashboard Agences & Agents Actifs"),
    html.Div([
        html.Div(f"Total Agences : {total_agences}", style={'display':'inline-block', 'margin-right':'2rem'}),
        html.Div(f"Total Agents Actifs : {total_agents_actifs}", style={'display':'inline-block'})
    ], style={'margin-bottom':'1rem'}),

    dcc.Dropdown(
        id='agence-selector',
        options=options,
        value='ALL',
        clearable=False,
        style={'width':'40%','margin-bottom':'1rem'}
    ),

    dcc.Graph(id='bar-roles'),

    dash_table.DataTable(
        id='table-agents',
        columns=[
            {"name":"Agence ID", "id":"agence_id"},
            {"name":"Agent ID",  "id":"agent_id"},
            {"name":"Nom",       "id":"nom"},
            {"name":"R√¥le",      "id":"role"},
            {"name":"Actif",     "id":"actif", "type":"numeric"}
        ],
        data=[],
        filter_action="native",
        sort_action="native",
        page_size=10,
        style_table={'overflowX':'auto'},
        style_cell={'whiteSpace':'normal','height':'auto'}
    )
])
@app.callback(
    [Output('bar-roles','figure'),
     Output('table-agents','data')],
    [Input('agence-selector','value')]
)
def update_dashboard(selected_agence):
    # 3.1 Filtrer selon s√©lection
    if selected_agence == 'ALL':
        df_sel = df_active.copy()
        title = "Agents Actifs par R√¥le (toutes agences)"
    else:
        df_sel = df_active[df_active['agence_id'] == selected_agence]
        agence_name = df_agences.loc[df_agences['agence_id']==selected_agence,'agence_name'].iat[0]
        title = f"Agents Actifs par R√¥le ‚Äì Agence {agence_name} (ID {selected_agence})"

    # 3.2 Bar chart des r√¥les
    df_counts = df_sel.groupby('role').size().reset_index(name='count')
    fig = px.bar(
        df_counts,
        x='role', y='count',
        title=title,
        labels={'role':'R√¥le','count':'Nombre d‚Äôagents'},
        color='role',
        color_discrete_sequence=px.colors.qualitative.Pastel
    )
    fig.update_layout(xaxis_tickangle=-45, showlegend=False)

    # 3.3 Table des agents
    table_data = df_sel[['agence_id','agent_id','nom','role','actif']].to_dict('records')

    return fig, table_data
if __name__ == '__main__':
    app.run(debug=True)

"""#Carte Thermique Temporelle

"""

import mysql.connector
import pandas as pd
conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)

df_employer= pd.read_sql("SELECT * FROM  employeurs ", conn)
conn.close()


for col in df_ag.columns:
    print(col)
print("--------------------------")
for col in df_employer.columns:
    print(col)
print("---------------------------")
for col in df_offres.columns :
    print(col)

!pip install geopandas scikit-learn folium
import numpy as np
import pandas as pd
from sklearn.cluster import DBSCAN
import folium
from folium.plugins import HeatMap, MarkerCluster

# G√©n√©ration de donn√©es simul√©es pour la Mauritanie
np.random.seed(42)

# Cr√©ation de 3 zones chaudes artificielles
hotspots = {
    'Nouakchott': {'lat': 18.0731, 'lng': -15.9582, 'size': 50},
    'Nouadhibou': {'lat': 20.9410, 'lng': -17.0384, 'size': 30},
    'Rosso': {'lat': 16.5125, 'lng': -15.8053, 'size': 20}
}

data = []
for city, params in hotspots.items():
    data.append(pd.DataFrame({
        'lat': params['lat'] + np.random.normal(0, 0.03, params['size']),
        'lng': params['lng'] + np.random.normal(0, 0.03, params['size']),
        'offres': np.random.randint(1, 20, params['size']),
        'commune': city
    }))

df = pd.concat(data)

# Clustering DBSCAN
coords = np.radians(df[['lat', 'lng']])
kms_per_radian = 6371.0088
epsilon = 20 / kms_per_radian  # 20 km radius

db = DBSCAN(
    eps=epsilon,
    min_samples=5,
    metric='haversine',
    algorithm='ball_tree'
).fit(coords)

df['cluster'] = db.labels_

# Cr√©ation de la carte
m = folium.Map(location=[18.0731, -15.9582], zoom_start=6)

# Couleurs pour les clusters
colors = ['#FF0000', '#00FF00', '#0000FF', '#FFA500', '#800080']

# Ajout des clusters
marker_cluster = MarkerCluster().add_to(m)

for idx, row in df.iterrows():
    color = colors[row['cluster'] % len(colors)] if row['cluster'] != -1 else '#808080'

    folium.CircleMarker(
        location=[row['lat'], row['lng']],
        radius=row['offres']*0.5,
        color=color,
        fill=True,
        fill_opacity=0.7,
        popup=f"Commune: {row['commune']}<br>Offres: {row['offres']}"
    ).add_to(marker_cluster)

# Ajout de la heatmap
HeatMap(
    data=df[['lat', 'lng', 'offres']].values.tolist(),
    radius=20,
    blur=15,
    max_zoom=12
).add_to(m)

# Ajout des contours des clusters
for cluster_id in df['cluster'].unique():
    if cluster_id != -1:
        cluster_points = df[df['cluster'] == cluster_id][['lat', 'lng']]
        folium.Polygon(
            locations=cluster_points.values.tolist(),
            color=colors[cluster_id],
            fill=True,
            fill_opacity=0.1
        ).add_to(m)

m

import pandas as pd

# R√©cup√©rez le nom de l'agence depuis df_ag
df = df_employer.merge(
    df_ag[['id','libelle']].rename(columns={'id':'agence_id','libelle':'agence_name'}),
    on='agence_id', how='left'
)

# V√©rifiez la jointure
df[['latitude','longitude','agence_id','agence_name']].head()

import numpy as np
from sklearn.cluster import DBSCAN


# Replace None values with NaN
df[['latitude', 'longitude']] = df[['latitude', 'longitude']].fillna(np.nan)

# Drop rows with NaN values in 'latitude' or 'longitude'
df = df.dropna(subset=['latitude', 'longitude'])
# Convertissez vos colonnes lat/lng en radians
coords = np.radians(df[['latitude','longitude']])

# D√©finissez un rayon de 20 km (en radians)
kms_per_radian = 6371.0088
epsilon = 20 / kms_per_radian

# Lancez DBSCAN
db = DBSCAN(
    eps=epsilon,
    min_samples=5,
    metric='haversine',
    algorithm='ball_tree'
).fit(coords)

df['cluster'] = db.labels_   # -1 = bruit, 0,1,2... = clusters

# V√©rifier un √©chantillon pour voir o√π sont vos coordonn√©es
print(df_employer.columns)

print(df_employer[['lat','lng','latitude','longitude']].head(10))

import pandas as pd
import numpy as np
from sqlalchemy import create_engine
from geopy.geocoders import Nominatim                              # Geocoder Nominatim :contentReference[oaicite:0]{index=0}
from geopy.extra.rate_limiter import RateLimiter                   # Pour limiter le nombre de requ√™tes :contentReference[oaicite:1]{index=1}
import folium                                                     # Cartographie interactive
from folium.plugins import MarkerCluster, HeatMap                  # Clustering et heatmap
from IPython.display import display
# 3.1 Cr√©ation du g√©ocodeur Nominatim
geolocator = Nominatim(user_agent="mon_app_agences")  # user_agent requis :contentReference[oaicite:2]{index=2}

# 3.2 Wrap dans un RateLimiter pour ajouter un d√©lai de 1 s entre les requ√™tes
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1, swallow_exceptions=True)

# 3.3 G√©ocoder : obtention d‚Äôun objet Location ou None
df_ag['location'] = df_ag['adresse'].apply(geocode)

# 3.4 Extraction des coordonn√©es ou NaN
df_ag['lat'] = df_ag['location'].apply(lambda loc: loc.latitude if loc else np.nan)
df_ag['lng'] = df_ag['location'].apply(lambda loc: loc.longitude if loc else np.nan)

# 3.5 V√©rification
print(df_ag[['libelle','adresse','lat','lng']].head(10))

# 4.1 Centre de la carte sur le barycentre des agences
center = [df_ag['lat'].mean(), df_ag['lng'].mean()]
m = folium.Map(location=center, zoom_start=6, tiles='CartoDB Positron')

# 4.2 MarkerCluster pour grouper les marqueurs proches
marker_cluster = MarkerCluster().add_to(m)

# 4.3 Ajout de cercles pour chaque agence
for _, row in df_ag.dropna(subset=['lat','lng']).iterrows():
    popup = f"<b>{row['libelle']}</b><br>{row['adresse']}"
    folium.CircleMarker(
        location=[row['lat'], row['lng']],
        radius=6,
        color='blue',
        fill=True,
        fill_color='cyan',
        fill_opacity=0.7,
        popup=popup
    ).add_to(marker_cluster)

# 4.4 HeatMap pour visualiser la densit√© (optionnel)
if 'nb_sites' in df_ag.columns:
    HeatMap(
        data=df_ag[['lat','lng','nb_sites']].values.tolist(),
        radius=15, blur=10, max_zoom=12
    ).add_to(m)

# 4.5 Affichage dans Colab/Jupyter
display(m)

conn = pymysql.connect(
    user='ap6ei_taleb',
    password='1Z_z8H~z7a$N@x',
    host='ap6ei.myd.infomaniak.com',
    database='ap6ei_test_delil'
)
df_agent = pd.read_sql("SELECT * FROM  agents ", conn)


print(df_employer, df_ag.columns, df_agent.columns)

# 2.1 Dictionnaire de correspondance des fonctions
role_map = {
    1: "Conseiller",
    2: "Chef",
    3: "Administrateur",
    # ‚Ä¶ autres mappings ‚Ä¶
}

# 2.2 Joindre df_emp ‚Üí df_agent pour r√©cup√©rer la fonction de chaque agent
df = (
    df_employer
    .merge(df_agent[['id','ref_fonctions_agent_id']].rename(columns={'id':'agent_id'}),
           on='agent_id', how='left')
    .merge(df_ag[['id','libelle']].rename(columns={'id':'agence_id','libelle':'agence_name'}),
           on='agence_id', how='left')
)

# 2.3 Remplacer l‚ÄôID de fonction par son nom
df['fonction'] = df['ref_fonctions_agent_id'].map(role_map).fillna("Inconnu")

# 2.4 Compter le nombre d‚Äôemployeurs par agence et par fonction
counts = (
    df
    .groupby(['agence_id','agence_name','fonction'])
    .size()
    .reset_index(name='n_agents')
)

# 3.1 Transformer en wide format : une colonne par fonction
pivot = counts.pivot_table(
    index=['agence_id','agence_name'],
    columns='fonction',
    values='n_agents',
    fill_value=0
).reset_index()

!pip install geopy folium pandas --quiet


import pandas as pd
import numpy as np
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
import folium
from folium.plugins import MarkerCluster
from IPython.display import display

df_ag = pd.DataFrame({
    'agence_name': [
        'Ksar','Tevragh Zeina','Centrale','Arafat','Bogh√©','Akjoujt','Dar Naim',
        'Nouadhibou','Kiffa','Kaedi','N√©ma','S√©libabi','A√Øoun','Zouerate',
        'Tidjikja','Atar','Rosso','Aleg old','Aleg','Basseknou','Agence STAGI',
        'Babab√©',"M'bagne",'Mal','Maghta-Lahjar'
    ]
})
df_ag['latitude'] = np.nan
df_ag['longitude'] = np.nan

geolocator = Nominatim(user_agent="mon_app_agences")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

def geocode_agence(name):
    """Renvoie (lat, lng) ou (np.nan, np.nan) si √©chec."""
    try:
        loc = geocode(f"{name}, Mauritanie")
        return (loc.latitude, loc.longitude) if loc else (np.nan, np.nan)
    except Exception:
        return (np.nan, np.nan)


df_ag[['lat','lng']] = df_ag['agence_name'].apply(
    lambda n: pd.Series(geocode_agence(n))
)


center = [df_ag['lat'].mean(), df_ag['lng'].mean()]
m = folium.Map(location=center, zoom_start=6, tiles='CartoDB Positron')

marker_cluster = MarkerCluster().add_to(m)

for _, row in df_ag.dropna(subset=['lat','lng']).iterrows():
    folium.CircleMarker(
        location=[row['lat'], row['lng']],
        radius=7,
        color='blue',
        fill=True,
        fill_color='cyan',
        fill_opacity=0.7,
        popup=f"<b>{row['agence_name']}</b>"
    ).add_to(marker_cluster)

display(m)

# Dashboard and Map: Agents and Employeurs by Agency
# This script combines data loading, aggregation, clustering, and Folium map visualization

import pandas as pd
import numpy as np
from sqlalchemy import create_engine
from sklearn.cluster import DBSCAN
import folium
from folium.plugins import MarkerCluster, HeatMap
from IPython.display import display
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter

# Initialize geolocator and rate limiter
geolocator = Nominatim(user_agent="mon_app_agences")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

# Ensure df_ag has 'latitude' and 'longitude' columns
if 'latitude' not in df_ag.columns:
    df_ag['latitude'] = np.nan
if 'longitude' not in df_ag.columns:
    df_ag['longitude'] = np.nan

# Geocoding function
def geocode_agence(name):
    try:
        loc = geocode(f"{name}, Mauritanie")
        return (loc.latitude, loc.longitude) if loc else (np.nan, np.nan)
    except Exception:
        return (np.nan, np.nan)

# Apply geocoding for rows with missing coordinates
df_ag[['latitude','longitude']] = df_ag.apply(
    lambda row: pd.Series(geocode_agence(row['libelle'])), axis=1
)

# 4. Role mapping for agents
role_map = {1: "Conseiller", 2: "Chef", 3: "Administrateur"}

# 5. Aggregate agent counts by agency and function
agent_counts = (
    df_agent
    .groupby(['agence_id', 'ref_fonctions_agent_id'])
    .size()
    .reset_index(name='n_agents')
    .pivot(index='agence_id', columns='ref_fonctions_agent_id', values='n_agents')
    .fillna(0)
    .rename(columns=role_map)
    .reset_index()
)

# 6. Aggregate employer counts by agency
emp_counts = (
    df_emp
    .groupby('agence_id')
    .size()
    .reset_index(name='n_employeurs')
)

# 7. Merge all info into agency dataframe
df_popup = (
    df_ag.rename(columns={'id':'agence_id','libelle':'agence_name'})
         .merge(agent_counts, on='agence_id', how='left')
         .merge(emp_counts,   on='agence_id', how='left')
         .fillna(0)
)

# 8. (Optional) DBSCAN clustering on agency coordinates if available
if df_popup['latitude'].notna().all() and df_popup['longitude'].notna().all():
    coords = np.radians(df_popup[['latitude','longitude']])
    kms_per_radian = 6371.0088
    epsilon = 20 / kms_per_radian
    db = DBSCAN(eps=epsilon, min_samples=2, metric='haversine', algorithm='ball_tree').fit(coords)
    df_popup['cluster'] = db.labels_

# 9. Create Folium map
m = folium.Map(
    location=[df_popup['latitude'].mean(), df_popup['longitude'].mean()],
    zoom_start=6,
    tiles='CartoDB Positron'
)
marker_cluster = MarkerCluster().add_to(m)

# 10. Add markers with detailed popups
for _, row in df_popup.iterrows():
    popup_html = f"<b>{row['agence_name']}</b><br>"
    # Add agent roles counts
    for role in role_map.values():
        popup_html += f"{role}: {int(row.get(role,0))}<br>"
    # Add employers count
    popup_html += f"Employeurs: {int(row.get('n_employeurs',0))}"
    folium.CircleMarker(
        location=[row['latitude'], row['longitude']],
        radius=7,
        color='darkblue',
        fill=True,
        fill_color='cyan',
        fill_opacity=0.7,
        popup=popup_html
    ).add_to(marker_cluster)

# 11. Optional heatmap of employers
if 'latitude' in df_popup.columns and 'longitude' in df_popup.columns:
    HeatMap(
        data=df_popup[['latitude','longitude','n_employeurs']].values.tolist(),
        radius=15, blur=10, max_zoom=12
    ).add_to(m)

# 12. Display map
display(m)